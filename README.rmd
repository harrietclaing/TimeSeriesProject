---
title: "TimeSeries Project"
output: html_document
---

# Purpose
To replicate the study by Cologni & Manera to find the economic impact of a rise in oil prices.

```{r}
rm(list = ls()) # Clean your environment:
gc() # garbage collection - It can be useful to call gc after a large object has been removed, as this may prompt R to return memory to the operating system.
library(tidyverse)
library(zoo)
library(tseries)
library(vars)
library(urca)
library(AICcmodavg)
library(ggplot2)
library(ggfortify)
```
# Step 1: Find the data

Tried to find all data from the IMF, but for Exchange Rates had to use OECD estimates and for Inflation had to use US Bureau of Labor Statistics. First, we want to use US data and see if we can replicate the results in the study. We need to convert all the data into quarterly and limit the time period to the one used in the paper which is from 1980Q1 to 2003Q3. World oil price: could only find from 1990, therefore had to limit to 1990 onwards.

```{r}
#convert monthly to quarterly & change
 

WorldOilPricedollars <- GlobalPriceofBrentCrudeUSDollars %>% 
                        group_by(DATE = format(as.yearqtr(DATE, "%b-%Y"), "%YQ%q"))%>%
                        summarise_all(mean) %>% 
                        filter(DATE>"1979Q4" & DATE<"2003Q4")

WorldOilPrice_dollars <- data.frame(DATE=WorldOilPricedollars$DATE, WorldOilPrice=WorldOilPricedollars$POILBREUSDM)
```
Interest rates ($r_t$)
```{r}
#rename column in dataframe
InterestRateUS_ <- rename(InterestRateUS, InterestRate=INTDSRUSM193N)

#convert monthly to quarterly

InterestRates_US <- InterestRateUS_ %>% 
    group_by(DATE = format(as.yearqtr(DATE, "%b-%Y"), "%YQ%q")) %>%
    summarise_all(mean) %>% 
    filter(DATE>"1989Q4" & DATE<"2003Q4")
#we want to filter to get the correct time frame
```
Inflation ($p_t$)
```{r}
#rename column in dataframe
InflationUS_ <- rename(InflationUSBLSUS, Inflation=CPIAUCSL)

#convert monthly to quarterly

Inflation_US <- InflationUS_ %>% 
    group_by(DATE = format(as.yearqtr(DATE, "%b-%Y"), "%YQ%q")) %>%
    summarise_all(mean) %>% 
    filter(DATE>"1989Q4" & DATE<"2003Q4") #one period back to get a change later on
#we want to filter to get the correct time frame
```
Monetary aggregates ($M_t$)
```{r}
#rename column in dataframe
MonetaryAggregateM1US_ <- rename(MonetaryAggregateM1US, MonetaryAggregate=MYAGM1USM052S)

#convert monthly to quarterly

MonetaryAggregateM1_US <- MonetaryAggregateM1US_ %>% 
    group_by(DATE = format(as.yearqtr(DATE, "%b-%Y"), "%YQ%q")) %>%
    summarise_all(mean) %>% 
    filter(DATE>"1989Q4" & DATE<"2003Q4")
#we want to filter to get the correct time frame
```
Exchange rates ($e_t$)
```{r}
#rename column in dataframe
ExchangeRatesOECDUS_ <- rename(ExchangeRatesOECDUS, ExchangeRate=CCUSSP01IFM650N)

#convert monthly to quarterly

ExchangeRates_US <- ExchangeRatesOECDUS_ %>% 
    group_by(DATE = format(as.yearqtr(DATE, "%b-%Y"), "%YQ%q")) %>%
    summarise_all(mean) %>% 
    filter(DATE>"1989Q4" & DATE<"2003Q4")
#we want to filter to get the correct time frame
```
For real GDP, we have quarterly, so we will need to simply isolate the time period.
```{r}
#rename column in dataframe
RealGDPUS_ <- rename(RealGDPUS, RealGDP=NGDPRSAXDCUSQ)

RealGDP_US <- RealGDPUS_ %>% 
                group_by(DATE = format(as.yearqtr(DATE, "%b-%Y"), "%YQ%q")) %>%
                filter(DATE>"1989Q4" & DATE<"2003Q4")
#we want to filter to get the correct time frame
```

# Step 2: Transform the data 

Next step is to transform all I(1) variables in logs, except for the interest rate. 

```{r}
logRealGDP_US <- data.frame(DATE=RealGDP_US$DATE, logRealGDP=log(RealGDP_US$RealGDP))
logExchangeRates_US <-data.frame(DATE=ExchangeRates_US$DATE, logExchangeRates=log(ExchangeRates_US$ExchangeRate))
logWorldOilPrice <- data.frame(DATE=WorldOilPrice_dollars$DATE, logWorldOilPrice=log(WorldOilPrice_dollars$WorldOilPrice))
```

But according to the paper, different transformations for the I(2) series of Monetary Aggregates and Inflation. The plot for logInflation and Inflation both show almost identical linear upward trends.

First need to create a dataframe with both Monetary Aggregates and Inflation.
```{r}
dfMonetaryAggregate_Inflation <- data.frame(DATE=MonetaryAggregateM1_US$DATE, Inflation=Inflation_US$Inflation, MonetaryAggregateM1= MonetaryAggregateM1_US$MonetaryAggregate)
```
Then transform the Monetary Aggregate (does not make much difference)
```{r}
TransformedMonetaryAggregateM1_US <- mutate(dfMonetaryAggregate_Inflation, TransformedMonetaryAggregateM1 = MonetaryAggregateM1-Inflation)
TransformedMonetaryAggregateM1_US
```
Then, change in price level:
```{r}
#first need to extend back one period to avoid 0 results
Inflation_US1 <- InflationUS_ %>% 
    group_by(DATE = format(as.yearqtr(DATE, "%b-%Y"), "%YQ%q")) %>%
    summarise_all(mean) %>% 
    filter(DATE>"1989Q3" & DATE<"2003Q4")

TransformedInflation_US <- mutate(Inflation_US1, TransformedInflation = Inflation_US1$Inflation - lag(Inflation_US1$Inflation, default=first(Inflation_US1$Inflation)))
```

# Step 3: Augemented Dickey-Fuller tests

The null-hypothesis of an Augmented Dickey-Fuller test is that the series has a unit-root. We ask, is the estimated critical value small enough to reject the null-hypothesis? If yes, we cannot reject the null hypothesis, therefore, the series may be non-stationary.

Interest Rate
```{r}
#let us visualise first
ggplot() +
    geom_point(aes(InterestRates_US$DATE, InterestRates_US$InterestRate))
```
No clear trend in the series.

```{r}
adf.InterestRate <- ur.df(InterestRates_US$InterestRate, type = "none", selectlags = c("AIC"))
summary(adf.InterestRate)
```
The estimated critical value is not small enough to reject the null hypothesis at any confidence interval, ie -1.5147 > -2.6

Inflation
```{r}
ggplot() +
    geom_point(aes(logInflation_US$DATE, logInflation_US$logInflation))
```
Clear upward trend, looks linear

```{r}
adf.Inflation <- ur.df(Inflation_US$Inflation, type = "none", selectlags = c("AIC"))
summary(adf.Inflation)
```
The estimated critical value of 4.7033 is not small enough to reject the null hypothesis, 4.7033 > -2.6. Therefore cannot reject the null hypothesis that there is a unit root.

Real GDP
```{r}
ggplot() +
    geom_point(aes(logRealGDP_US$DATE, logRealGDP_US$logRealGDP))
```
Clear upward trend, linear

```{r}
adf.RealGDP <- ur.df(logRealGDP_US$logRealGDP, type = "none", selectlags = c("AIC"))
summary(adf.RealGDP)
```
The estimated critical value is not small enough to reject the null hypothesis of a unit root, 5.6119 > -2.6.

Monetary Aggregates
```{r}
ggplot() +
    geom_point(aes(logMonetaryAggregateM1_US$DATE, logMonetaryAggregateM1_US$logMonetaryAggregateM1))
```
Increasing linear trend up to a point and then increasing at slower rate and fluctuates

```{r}
adf.MonetaryAggregate <- ur.df(logMonetaryAggregateM1_US$logMonetaryAggregateM1, type = "none", selectlags = c("AIC"))
summary(adf.MonetaryAggregate)
```
2.9491 > -2.6 therefore cannot reject the null hypothesis of unit root

Exchange Rate
```{r}
ggplot() +
    geom_point(aes(logExchangeRates_US$DATE, logExchangeRates_US$logExchangeRates))
```
Fluctuating series

```{r}
adf.ExchangeRates <- ur.df(logExchangeRates_US$logExchangeRates, type = "none", selectlags = c("AIC"))
summary(adf.ExchangeRates)
```
0.0214 >-2.6 therefore cannot reject the unit root


# Set up the VAR model

```{r}
df_US <- data.frame(InterestRate=InterestRates_US$InterestRate, Inflation= TransformedInflation_US$TransformedInflation, RealGDP=logRealGDP_US$logRealGDP, MonetaryAggregate=TransformedMonetaryAggregateM1_US$TransformedMonetaryAggregateM1, ExchangeRates=logExchangeRates_US$logExchangeRates, WorldOilPrice=WorldOilPrice_dollars$WorldOilPrice)

matrix_US <- as.matrix(df_US)

# nr_lev <- nrow(df.lev)
```
Now we have our VAR model in matrix form and data frame form...now we need to check the number of cointegrating relationships, stationarity and white noise residuals.

## Declare time series variables

```{r}
interestrate <- ts(InterestRates_US$InterestRate, start=c(1990,1), end=c(2003, 3), freq=4)
inflation <- ts(TransformedInflation_US$TransformedInflation, start=c(1990,1), end=c(2003,3), freq=4)
realGDP <- ts(logRealGDP_US$logRealGDP, start=c(1990,1), end=c(2003,3), freq=4)
exchangerate <- ts(logExchangeRates_US$logExchangeRates, start=c(1990,1), end=c(2003,3), freq=4)
worldoilprice <- ts(logWorldOilPrice$logWorldOilPrice, start=c(1990,1), end=c(2003,3), freq=4)
monetaryaggregate <- ts(TransformedMonetaryAggregateM1_US$TransformedMonetaryAggregateM1, start=c(1990,1), end=c(2003,3), freq=4)
```

## Plot time series variables
```{r}
autoplot(cbind(interestrate, inflation, realGDP, exchangerate, worldoilprice, monetaryaggregate))
```
## ACF & PACF
```{r}
acf(interestrate)
#find first four quarters ie first lag is signif
pacf(interestrate)
#find first, second and fourth quarter are signif
```
```{r}
acf(inflation)
#find no signif lags for either
pacf(inflation)
```
```{r}
acf(realGDP)
#lots of persistance, up to the third lag, ie quarter 13
pacf(realGDP)
#no autoreg persistance
```
```{r}
acf(monetaryaggregate)
#up to 7th quarter, ie one lag plus some
pacf(monetaryaggregate)
#not much signif
```
```{r}
acf(exchangerate)
#signif up to 6th quarter, one lag plus some
pacf(exchangerate)
# not much
```
```{r}
acf(worldoilprice)
#one lag
pacf(worldoilprice)
#only one quarter, not much
```

## Find optimal lags
```{r}
groupedVAR <- cbind(interestrate, inflation, realGDP, monetaryaggregate, exchangerate, worldoilprice)
colnames(groupedVAR) <- cbind("InterestRate", "Inflation", "RealGDP", "MonetaryAggregate", "ExchangeRate", "WorldOilPrice")
```
```{r}
lagselect <- VARselect(groupedVAR, lag.max=10, type="trend")
lagselect$selection
```
AIC, HQ and SC tests all suggest 8 lags should be included.

## Build model
```{r}
ModelUS <- VAR(groupedVAR, p=8, type="trend", season=NULL, exog=NULL)
#summary(ModelUS)
#OVERFITTING?? NOT ENOUGH OBSERVATIONS?
```
# Step 4: Johansen Test in the Long-Run Approach

```{r}
jotestTrace_US <- ca.jo(matrix_US, type="trace", K=2, ecdet="trend", spec="longrun") #incl linear trend as per paper
summary(jotestTrace_US)
```
For the trace test, we find one cointegrating relationship.

```{r}
jotestEigen_US <- ca.jo(matrix_US, type="eigen", K=2, ecdet="trend", spec="longrun") #incl linear trend as per paper
summary(jotestEigen_US)
```
For the eigenvalue test, we find that we can reject the null hypothesis of the number of cointegrating relationships equalling 2 or exceeding it, therefore, we conclude from our estimates that there is one cointegrating relationship.

# Step 5: ACF & PACF? or AIC criteria to choose lags

```{r}

```


# Step 6: Is it stationary?

# Step 7: Are the residuals white noise?
```{r}
#ljungbox test
```


# Step 8: Find VECM model by imposing SR contemporaneous effects

# Step 9: Test model specification using congruency, parsimony, lag inclusion...

